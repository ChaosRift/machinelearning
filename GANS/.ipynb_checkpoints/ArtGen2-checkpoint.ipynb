{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current work in progress\n",
    "    This is a standard no frills GAN with the exception the noise data is the shape of the current image batch. So you can use the standard gausian noise or actual images to train the GAN. \n",
    "    Current \"experiement is training the GAN on one set of data and the discriminator on real world photos. I want to see what will happen essentially. \n",
    "    \n",
    "### Data Science and Machine Learning is 80% experiementation and \"seeing what happens\". \n",
    "    Sure I could follow exactly what everyone else does but that doesn't benefit me or learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVnF24NFcuQ6"
   },
   "source": [
    "## **Mount Google Drive to store files & data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SFGfqdZphji"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0W_asugimDV"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow_addons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJp-D51g0IDd"
   },
   "source": [
    "## **1) Importing Python Packages for GAN**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXm8CNeB3MO4"
   },
   "outputs": [],
   "source": [
    "# Standard imports \n",
    "\n",
    "import sys\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from IPython import display\n",
    "#from matplotlib import cm\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k5mFBuzzl2a"
   },
   "outputs": [],
   "source": [
    "# Machine learning Imports. \n",
    "\n",
    "# from keras.datasets import cifar10, mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten, GlobalAveragePooling1D \n",
    "from tensorflow.keras.layers import Conv2D, Dense, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "# look this shit up.\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Class\n",
    "*Because it's cleaner avoids messy globals and scope ambiguity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    gan_name = \"AnimeHorrorGan\"\n",
    "    \n",
    "    runningColab = False\n",
    "    windows_base_path = \"F:\\\\machine_learning\"\n",
    "    colab_base_path = \"/content/drive/MyDrive/TensorFlow\"\n",
    "    \n",
    "    # Migrating to training generator on horror\n",
    "    # and discriminator on real images. Seeing if it will transpose or fail. \n",
    "    dataset = \"current_dataset\"\n",
    "    save_loc = \"generated_images\"\n",
    "    test_images_path = \"F:\\machine_learning\\datasets\\cats_dataset\"\n",
    "    test_images = []\n",
    "\n",
    "    # Final location defaults.\n",
    "    # gets overwritten depending on Colab or Local. \n",
    "    model_save_path = f\"{windows_base_path}\\\\my_models\"\n",
    "    dataset_path = join(windows_base_path, \"datasets\", dataset) # iput\n",
    "\n",
    "    \n",
    "    # I should save generated images in a different dir. This was due to ADHD. \n",
    "    generated_path = join(windows_base_path, \"datasets\", save_loc) # output\n",
    "    \n",
    "    generator_file = join(model_save_path, f\"{gan_name}_generator.h5\")\n",
    "    discriminator_file = join(model_save_path, f\"{gan_name}_discriminator.h5\")\n",
    "\n",
    "    batch_size = 5\n",
    "\n",
    "    img_width = 512\n",
    "    img_height = 512\n",
    "    channels = 3\n",
    "    img_shape = (img_width, img_height, channels)\n",
    "\n",
    "    latent_dim = 100 # Not really used anymore.\n",
    "    seed = 42\n",
    "    \n",
    "    files = []\n",
    "    batches_per_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoRqPt1DwtD_"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    Config.runningColab = True\n",
    "print ('Running in colab:', Config.runningColab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.runningColab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRWx5D09dX3p"
   },
   "outputs": [],
   "source": [
    "# Bit more work switching between local and Colab\n",
    "if Config.runningColab:\n",
    "    Config.generated_path = join(Config.colab_base_path, \"datasets\", Config.save_loc) # output\n",
    "    Config.dataset_path = join(Config.colab_base_path, \"datasets\", Config.dataset)\n",
    "    Config.model_save_path = join(Config.colab_base_path, \"models\")\n",
    "else:\n",
    "    Config.generated_path = join(Config.windows_base_path, \"datasets\", Config.save_loc) # output\n",
    "    Config.dataset_path = join(Config.windows_base_path, \"datasets\", Config.dataset)\n",
    "    Config.model_save_path = join(Config.windows_base_path, \"my_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UunJuxihuwnY"
   },
   "outputs": [],
   "source": [
    "if not exists(Config.generated_path):\n",
    "    print(f\"Creating {Config.generated_path}\")\n",
    "    os.mkdir(Config.generated_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr-eZOzg0X79"
   },
   "source": [
    "## **2) Parameters for Neural Networks & Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaoY5WTbi4dJ"
   },
   "source": [
    "## **Function Defs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jX4q_Vq3MO6"
   },
   "outputs": [],
   "source": [
    "def plant_seeds(seed=42):\n",
    "    Config.seed = seed\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "plant_seeds(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(num_images_to_gen):\n",
    "    # num_images_to_gen long way to say \"Batch size\". \n",
    "    #result = tf.random.normal(shape=[num_images_to_gen, latent_dim])\n",
    "    #result = tf.random.normal(shape=[num_images_to_gen, Config.img_width, Config.img_height, Config.channels], mean=0.0, stddev=1)\n",
    "    result = tf.random.uniform(shape=[num_images_to_gen, Config.img_width, Config.img_height, Config.channels], minval=-1.0, maxval=1.0, seed=Config.seed)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cropping, will probably use this for all images since this is resizing and creating new hash. \n",
    "def name_image(img):\n",
    "    hashedImage = hashlib.md5(img.tobytes()).hexdigest()\n",
    "    hashedName = hashedImage + \".\" + \"jpg\"\n",
    "    return hashedName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fW6DAG4_3MO7"
   },
   "outputs": [],
   "source": [
    "# Decode a single image in a TFRecord\n",
    "# It also standardizes the image\n",
    "# Not really needed since this is done in Numpy\n",
    "def decode_image(image) -> tf.Tensor:\n",
    "    #img = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    img = image / 127.5 - 1\n",
    "    print(type(img))\n",
    "    img = tf.reshape(img, [Config.img_width, Config.img_height, Config.channels])\n",
    "    #print(img.shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLWo-F1C3MO7"
   },
   "outputs": [],
   "source": [
    "# This is technically how you're supposed to do it. \n",
    "# I don't use this function.\n",
    "def dataset_from_dir(dataset_folder, ordered=False):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        dataset_folder,\n",
    "        labels=None,\n",
    "        #validation_split=0.2,\n",
    "        #subset=\"training\",\n",
    "        shuffle = False,\n",
    "        seed=Config.seed,\n",
    "        image_size=(Config.img_height, Config.img_width),\n",
    "        batch_size=1)\n",
    "    dataset = dataset.map(decode_image)\n",
    "    dataset = dataset.cache()\n",
    "    #dataset.shuffle(2048)\n",
    "    return dataset.batch(Config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_nkz3k6jZlm"
   },
   "outputs": [],
   "source": [
    "# Memory intensive. Use load_batch instead. \n",
    "# Loads it all into memory. Not Colab friendly. Works if you got 32G or more RAM. \n",
    "def dataset_manual(dataset_folder, max=0):\n",
    "    Config.imageNames = os.listdir(Config.dataset_path)\n",
    "    if max > 0:\n",
    "        imageNames = imageNames[:max]\n",
    "        print(f\"using {len(imageNames)} images.\")\n",
    "    array = []\n",
    "    for image in imageNames:\n",
    "        image = Image.open(join(resized_path, image))\n",
    "        data = np.asarray(image)\n",
    "        array.append(data)\n",
    "\n",
    "    X_train = np.array(array)\n",
    "    X_train = X_train / 127.5 -1.\n",
    "    print(X_train.shape)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_list(path):\n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        # Granted by the time I've created a dataset, there should only be jpg\n",
    "        # I may go png and just open with a .convert(\"RGB\") call later on. \n",
    "        for file in f:\n",
    "            if '.jpg' in file.lower() or '.png' in file.lower():\n",
    "                files.append(os.path.join(r, file))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab was running out of memory because loading all the datasets into memory burned out the VM. This solves that.\n",
    "# It was also easier to do it this way than the above creating datasets stuff. \n",
    "def load_batch(files, batchSize):\n",
    "    array = []\n",
    "    for i in range(batchSize):\n",
    "        # if there is less than 3 color channels, keep trying. \n",
    "        while True:\n",
    "            file = random.choice(files)\n",
    "            if not exists(file):\n",
    "                get_list_build_batches() # sometimes I'll just delete stuff while it's running. \n",
    "                continue\n",
    "            try:\n",
    "                image = Image.open(file).convert(\"RGB\")\n",
    "            except:\n",
    "                file = random.choice(files)\n",
    "                image = Image.open(file)\n",
    "                print(f\"Something occurred with {file}\")\n",
    "                \n",
    "            if image.size != (Config.img_width, Config.img_height): # not messing around. It doesn't fit, we'll make it fit. \n",
    "                print(f\"Resizing rogue image {file}.\")\n",
    "                image = image.resize((Config.img_width, Config.img_height))\n",
    "                image.save(file)\n",
    "            if len(image.split()) != 3:\n",
    "                print(f\"Removing {file}\")\n",
    "                os.remove(file)\n",
    "                get_list_build_batches()\n",
    "            else:\n",
    "                break\n",
    "        data = np.asarray(image)\n",
    "        data = data / 127.5 -1.\n",
    "        #print(data)\n",
    "        array.append(data)\n",
    "\n",
    "    train = np.array(array, dtype=np.float32)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyon's showe off their data code looks the same. :-p\n",
    "def show_batch(image_batch):\n",
    "    total_images = Config.batch_size\n",
    "    col_row = int(total_images/2)\n",
    "\n",
    "    plt.figure(figsize=(col_row,col_row))\n",
    "    for n in range():\n",
    "        ax = plt.subplot(10,10,n+1)\n",
    "        plt.imshow(image_batch[n, :, :, 0], cmap='gray')\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(name, source):\n",
    "    image = Image.fromarray(np.uint8(source*255))\n",
    "    image.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_build_batches():\n",
    "    print(f\"Getting file list and factoring how many batches per Epoch.\")\n",
    "    Config.files = get_images_list(Config.dataset_path)\n",
    "    epoch_batches = int(len(Config.files) / Config.batch_size )\n",
    "    epoch_batches = epoch_batches - (epoch_batches % Config.batch_size)\n",
    "    Config.batches_per_epoch = epoch_batches - (epoch_batches % Config.batch_size)\n",
    "    #return imageFiles, epoch_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaoY5WTbi4dJ"
   },
   "source": [
    "# **Load and visualize the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts how many batches per epoch will be used. Important really. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Py9whIfpG7jU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Builds list of images into array. Reduces file IO.\n",
    "#Config.imageFiles, Config.batches_per_epoch = get_list_build_batches()\n",
    "Config.test_images = get_images_list(Config.test_images_path)\n",
    "\n",
    "# batches based on generator dataset. \n",
    "get_list_build_batches()\n",
    "print(Config.batches_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization stuff. Can be skipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_batch(Config.files, Config.batch_size)\n",
    "#images = load_batch(Config.test_images, Config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the image manipulation and formatting here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.min(), images.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = (images + 1) / 2.0 # Changed from -1...1 to 0...1 for plt and save to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "Bm5MaRIPoSdA",
    "outputId": "908cb0ec-3b86-4a2d-b295-975018d98f4d"
   },
   "outputs": [],
   "source": [
    "image = random.choice(images)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "#save_image(\"batch_test.png\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xr_kKjt53MO8"
   },
   "outputs": [],
   "source": [
    "#X_train = dataset_from_dir(Config.dataset_path) \n",
    "#epoch_batches = len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Functions to build Gen/Disc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_instancenorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    result = keras.Sequential()\n",
    "    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_instancenorm:\n",
    "        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)) # Could also use batch normalization.\n",
    "\n",
    "    result.add(layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    result = keras.Sequential()\n",
    "    result.add(layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                      padding='same',\n",
    "                                      kernel_initializer=initializer,\n",
    "                                      use_bias=False))\n",
    "\n",
    "    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(layers.Dropout(0.5))\n",
    "\n",
    "    result.add(layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3bcJZZg0cqy"
   },
   "source": [
    "## **3) Building Generator**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdiqZpri0iQh",
    "outputId": "a3992edd-6de2-4a2b-b33f-65652112a64e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This one is OK, but it takes a flat noise and does things to make images. I've trained 200 epochs and still get junk. \n",
    "def Generator1():\n",
    "    multiplyer = int(((img_width/2)/2/2))\n",
    "    model = Sequential(name=\"Generator\")\n",
    "    model.add(Dense(img_width * multiplyer * multiplyer, input_dim=latent_dim)) # img_width was 256 here. \n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Reshape((multiplyer,multiplyer,img_width))) # img_width was 256 here. \n",
    "    \n",
    "    #model.add(BatchNormalization()) # Added\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(1,1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.3)) # activation leakey instead of old fashion RelU\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (2,2), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "\n",
    "    model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When building an image generator, it just makes sense they'd take in noise or an image of the same size it generates. \n",
    "def Generator2(width=512, height=512, channels=3):\n",
    "    inputs = layers.Input(shape=(width, height, channels))\n",
    "\n",
    "    # bs = batch size\n",
    "    # Conv2D\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_instancenorm=False), # (bs, 128, 128, 64)\n",
    "        downsample(64, 4), # (bs, 64, 64, 128) # added\n",
    "        downsample(128, 4), # (bs, 64, 64, 128)\n",
    "        downsample(256, 4), # (bs, 32, 32, 256)\n",
    "        downsample(512, 4), # (bs, 16, 16, 512)\n",
    "        downsample(512, 4), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    # convTranspose\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4), # (bs, 32, 32, 512)\n",
    "        upsample(128, 4), # (bs, 64, 64, 256)\n",
    "        upsample(64, 4), # (bs, 128, 128, 128)\n",
    "        upsample(64, 4), # (bs, 128, 128, 128) # added\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = layers.Conv2DTranspose(channels, 4,\n",
    "                                  strides=2,\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer=initializer,\n",
    "                                  activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=x, name=\"Generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator3(width=512, height=512, channels=3):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*1024, use_bias=False, input_shape=(None, width, height, channels)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 1024)))\n",
    "    assert model.output_shape == (None, 7, 7, 1024) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(512, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 512)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 28, 28, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 56, 56, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(2, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt6QsJCW0mcI"
   },
   "source": [
    "## **4) Building Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2JzEAPv0lKt",
    "outputId": "a59cc954-e46b-47a7-aaca-b83415f1e9ea"
   },
   "outputs": [],
   "source": [
    "def Discriminator1():\n",
    "    model = Sequential(name=\"Discriminator\")\n",
    "    model.add(Conv2D(64, (3,3), padding='same', input_shape=img_shape))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding='same', ))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator2(width=512, height=512, channels=3):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    inp = layers.Input(shape=(width, height, channels), batch_size=None)\n",
    "\n",
    "    x = inp\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "    zero_pad1 = layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "\n",
    "    conv = layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n",
    "    leaky_relu = layers.LeakyReLU()(norm1)\n",
    "    zero_pad2 = layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "    \n",
    "\n",
    "    last = layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "    last = Flatten()(last)\n",
    "    #last = Dropout(0.4)(last)\n",
    "    last = Dense(1, activation='sigmoid')(last)\n",
    "\n",
    "    return tf.keras.Model(inputs=inp, outputs=last, name=\"Discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator3(width=512, height=512, channels=3):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=1, strides=(2, 2), padding='same', input_shape=(width, height, channels)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=1, strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=1, strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=512, kernel_size=1, strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    #model.add(layers.Flatten())\n",
    "    model.add(GlobalAveragePooling1D (keepdims=False))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old way.\n",
    "#generator = Generator1()\n",
    "#discriminator = Discriminator1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator2(Config.img_width, Config.img_height, Config.channels)\n",
    "discriminator = Discriminator2(Config.img_width, Config.img_height, Config.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator = Generator3(Config.img_width, Config.img_height, Config.channels)\n",
    "#discriminator = Discriminator3(Config.img_width, Config.img_height, Config.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer stuff. Moved down here to be closer where it is used. \n",
    "\n",
    "# adam = Adam(learning_rate=0.002) # Default is 0.001\n",
    "\n",
    "# optimization level is different for each model. \n",
    "generator_optimizer = Adam(1e-4)\n",
    "discriminator_optimizer = Adam(1e-4)\n",
    "\n",
    "cross_entropy = BinaryCrossentropy(from_logits=False)\n",
    "loss = BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=loss, optimizer=discriminator_optimizer, metrics=['accuracy'])\n",
    "#discriminator.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE), optimizer=adam, metrics=['accuracy'])\n",
    "#discriminator.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "discriminator.trainable = False # Set to false before compiling main GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbcKcKmA0q2S"
   },
   "source": [
    "## **5) Connecting Neural Networks to build GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0Ue3TEd0xLy",
    "outputId": "4728b9c4-dd89-443d-d6e5-ea9b6a17f4ea"
   },
   "outputs": [],
   "source": [
    "GAN = Sequential(name=Config.gan_name)\n",
    "GAN.add(generator)\n",
    "GAN.add(discriminator)\n",
    "GAN.summary()\n",
    "\n",
    "GAN.compile(loss=loss, optimizer=generator_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPqU8dZDaQmE"
   },
   "outputs": [],
   "source": [
    "#generator.summary()\n",
    "#discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_backup(disc, gen):\n",
    "    print(\"Saving backup weights...\")\n",
    "    backup_gen_file = join(Config.model_save_path, f\"{Config.gan_name}_generator_{Config.seed}.h5\")\n",
    "    backup_disc_file = join(Config.model_save_path, f\"{Config.gan_name}_discriminator_{Config.seed}.h5\")\n",
    "    generator.save_weights(backup_gen_file)\n",
    "    discriminator.save_weights(backup_disc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_progress(disc, gen):\n",
    "    if exists(Config.generator_file):\n",
    "        print(\"Loading generator weights.\")\n",
    "        gen.load_weights(Config.generator_file)\n",
    "    if exists(Config.discriminator_file):\n",
    "        print(\"Loading discriminator weights.\")\n",
    "        disc.load_weights(Config.discriminator_file)\n",
    "    \n",
    "    # if nothing loads it just returns the same model. \n",
    "    return disc, gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_progress(disc, gen):\n",
    "    gen.save_weights(Config.generator_file)\n",
    "    disc.save_weights(Config.discriminator_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WaNhBDwRwTG"
   },
   "source": [
    "## Generating Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQEJ0WbjRppy"
   },
   "outputs": [],
   "source": [
    "def test_generator(epoch):\n",
    "    #generator, discriminator = GAN.layers\n",
    "    num_to_gen = 8\n",
    "    noise = make_noise(num_to_gen)\n",
    "    #noise = load_batch(Config.test_images, num_to_gen)\n",
    "    \n",
    "    gen_imgs = generator(noise, training=False)\n",
    "    gen_imgs = (gen_imgs + 1) / 2.0\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    print(f\"Generating {num_to_gen} test images.\")\n",
    "\n",
    "    for i in range(num_to_gen):\n",
    "        save_image(f\"{Config.generated_path}/{epoch}_{Config.gan_name}_{i}.jpg\", gen_imgs[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE57Lk5V0xs2"
   },
   "source": [
    "## **7) Training GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egSJJvik00Iq",
    "outputId": "a142d784-0d8e-48e3-8055-0388913c3879"
   },
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=32):\n",
    "    # Grab the seprate components\n",
    "    generator, discriminator = GAN.layers\n",
    "    \n",
    "    print(f\"training starting with {epochs} epochs of {Config.batches_per_epoch} total batches each. Batch size is {batch_size}\")\n",
    "\n",
    "    #Create our Y for our Neural Networks\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fakes = np.zeros((batch_size, 1))\n",
    "    \n",
    "    discriminator, generator = load_progress(discriminator, generator)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_batches = Config.batches_per_epoch # If it changes. \n",
    "        for j in range(epoch_batches):\n",
    "\n",
    "            #Phase 1: Generate fake images.\n",
    "            noise = make_noise(batch_size)\n",
    "            real_imgs = load_batch(Config.files, batch_size) #Get Random Batch\n",
    "            \n",
    "            # training_step usually a function. But really, easier to follow and adjust here. \n",
    "            #Phase 2: Train discriminator\n",
    "            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                fake_imgs = generator(noise, training=True)\n",
    "\n",
    "                discriminator.trainable = True # I think we forgot this so it never trained, ever. \n",
    "                loss_real = discriminator.train_on_batch(real_imgs, valid)\n",
    "                loss_fake = discriminator.train_on_batch(fake_imgs, fakes)\n",
    "                #loss_real = discriminator(real_imgs, training=True)\n",
    "                #loss_fake = discriminator(fake_imgs, training=True)\n",
    "                \n",
    "                noise = make_noise(batch_size)\n",
    "                gan_loss = GAN.train_on_batch(noise, valid)\n",
    "                \n",
    "                d_loss = discriminator_loss(loss_real, loss_fake)\n",
    "                g_loss = generator_loss(loss_fake)\n",
    "                \n",
    "                loss = 0.5 * np.add(loss_real, loss_fake)\n",
    "                accuracy = (100 * loss[1])\n",
    "                \n",
    "            discriminator.trainable = False\n",
    "            # Adjust optimizer learning rates. \n",
    "            #gradients_of_discriminator = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            #gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "\n",
    "            #generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "            #discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "            #d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "\n",
    "            # Phase 3: feed fake images to generator and set labels as \"real\". \n",
    "            #gen_train_imgs = load_batch(Config.gen_files, batch_size)\n",
    "            #noise = make_noise(batch_size)\n",
    "            #g_loss = GAN.train_on_batch(noise, valid)\n",
    "            \n",
    "            \n",
    "            if j % 50 == 0:\n",
    "                print(f\"******* Epoch: {epoch+1}/{epochs}: Batch {j}/{epoch_batches} [D loss: {d_loss:.6f}, acc: {accuracy:.2f}%] [G loss: {g_loss:.6f}]\")\n",
    "\n",
    "        print(f\"Saving weights: {generator_file}\")\n",
    "        save_progress(discriminator, generator)\n",
    "\n",
    "        # Sometimes I get a really great training and then later Epochs it gets wrecked. \n",
    "        # So I save every X epochs. \n",
    "        # **** This will take up a lot of disk space. \n",
    "        if epoch % 50 == 0:\n",
    "            display.clear_output(wait=True)\n",
    "            save_backup(discriminator, generator)\n",
    "        \n",
    "        test_generator(epoch+1)\n",
    "        \n",
    "        # Adding a seed after every epoch makes results close to impossible to reproduce. \n",
    "        # Seed is saved as part of the backup model name, so that's a start. \n",
    "        plant_seeds(int(time.time())) # New seedlings every Epoch. \n",
    "        \n",
    "    print(\"Training Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startover = True\n",
    "if startover:\n",
    "    generator_file = join(Config.model_save_path, f\"{Config.gan_name}_generator.h5\")\n",
    "    discriminator_file = join(Config.model_save_path, f\"{Config.gan_name}_discriminator.h5\")\n",
    "\n",
    "    print(\"Removing saved models.\")\n",
    "    if exists(generator_file):\n",
    "        # Gonna assume it's 2 for one.\n",
    "        os.remove(generator_file)\n",
    "        os.remove(discriminator_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(10, batch_size=Config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select this cel. Run all above :-p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kT7_Wk-TS_n2"
   },
   "outputs": [],
   "source": [
    "#generator, discriminator = GAN.layers\n",
    "\n",
    "# Finally made a function. \n",
    "discriminator, generator = load_progress(discriminator, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = make_noise(10)\n",
    "plt.imshow(noise[0])\n",
    "print(np.array(noise[0]).min(), np.array(noise[0]).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_imgs = generator(noise)\n",
    "print(np.array(gen_imgs[0]).min(), np.array(gen_imgs[0]).max())\n",
    "gen_imgs = (gen_imgs + 1) / 2.0\n",
    "print(np.array(gen_imgs[0]).min(), np.array(gen_imgs[0]).max())\n",
    "#gen_imgs = (gen_imgs * 255.).astype(int)\n",
    "#gen_imgs = np.clip(gen_imgs, 0, 255)\n",
    "#print(f\"{gen_imgs.shape}\\n{gen_imgs}\")\n",
    "#gen_imgs[0]\n",
    "#save_image(\"generated.png\", gen_imgs[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gen_imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_batch(Config.test_images, num_to_gen)\n",
    "imgs = np.expand_dims(img, axis=0)\n",
    "gen = generator(imgs)\n",
    "\n",
    "#conf prp1158022770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.shape\n",
    "gen = (gen + 1) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.3841858e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimages = load_batch(imageFiles, 10)\n",
    "testimages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator(testimages)\n",
    "#gen = (gen + 1) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(random.choice(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7ni_ubQ5CAg"
   },
   "outputs": [],
   "source": [
    "#gen_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbWAZ1v_TdJd"
   },
   "outputs": [],
   "source": [
    "plt.imshow(gen_imgs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8YtpQpkRvRI"
   },
   "outputs": [],
   "source": [
    "print(gen_imgs.min(), gen_imgs.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "po-jSQoN1Azl"
   },
   "source": [
    "### **8) Making GIF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPShgQpg1EMy"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "# def display_image(epoch_no):\n",
    "#   return PIL.Image.open('generated_images/%.8f.png'.format(epoch_no))\n",
    "\n",
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('generated_images/*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogrmQ73ZR_Wi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
