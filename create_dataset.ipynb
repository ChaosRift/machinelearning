{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511175ad-5b4e-4257-a7bd-3d695a29ace1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Usage Warning</b>\n",
    "    \n",
    "This script can and will destroy, disifgure and delete files. \n",
    "\n",
    "I don't mess around. If a file is in someway corrupt, out of place or the wrong type, cannot process properly... <b>it will get deleted.</b>\n",
    "\n",
    "There is a function that if you set the flag to \"True\" it will delete the original files. I run a clean and tight ship on my computer and don't want 400 copies laying around. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81191347-3f0b-47f2-985b-46bee9a6f88f",
   "metadata": {},
   "source": [
    "# Creates Datasets with the images.\n",
    "### By Craig Giannelli\n",
    "## Purpose\n",
    "    I was spending a lot of time on Google Image search looking for particular art for my GAN. I'd resize them to 512x dimenion with Topaz GigaPixel and then square crop with windows Photo (fast and easy)\n",
    "    Most data science classes don't teach collecting, formatting and creating your own datasets. Most use mnist, \"van Gogh\" or some other easily used premade datasets<br>\n",
    "    For my GANs I wanted unique datasets from images mined off the internet and Kaggle.<br>\n",
    "\n",
    "## Naming convention. \n",
    "    File names are created from a hash of the image and should be pretty unique. \n",
    "    It's also a nice way to shuffle your data.\n",
    "    Directory names will have _size_dataset appended \"bobross_512_dataset\"\n",
    "    For me, it tells the size and images were processed. It also leaves the source dir alone. \n",
    "\n",
    "## Sort or Resize\n",
    "    The main function *sort_or_resize* will grab a sample, to see if the images are square and the size desired. It will then either just copy to your dataset folder or crop/resize images to your needs.\n",
    "\n",
    "## Cropping\n",
    "    *resize_and_crop*\n",
    "    The crop function is mostly helper functions. It will do a brute estimate on your images and scale the image up/down based on the smallest dimension.\n",
    "    > Say you want (512x512) and the image is (890x315) It will do the maths to scale the image based on the 315 dimension. in this case 1.6x scaling for a rough 1140x512.\n",
    "    > but wait! there's more. It will now figure out to crop little images off of this new image, so it'll start left to right and crop out chunks. The last crop will intentionally have some overlap. In most cases a center crop is the most important.\n",
    "    > So for most images it can do a left/right crop, or a left, center, right crop with some overlap. If the ratio is 1.5 to 2 crops, it will do the 3 crop pattern. I find it had some cool results this way.\n",
    "    > For Portrait images, same logic just top/down instead of left/right.\n",
    "\n",
    "    My thinking is a GAN needs as much imagery as possible and this is just another form of data augmentation. It also keeps from feeding a GAN/Classifyer warped or distorted images from scaling non-square images. I'm OCD this way.\n",
    "    This method turned 1000 images into roughly 1500.\n",
    "    \n",
    "## Sorting\n",
    "    *sort_images*\n",
    "    Sorting is straighforward. Grabs images in a directory structure and moves them into your \"current\" dataset folder. It will also make numbered subdirectories so folders are kept to roughly 2000 files each. Cropping wrecks this and may be fixed someday.<br>\n",
    "    The logic on this is to avoid cross contamination of the datasets. You can mix and match datasets and then wipe out the directory without ever ruining the source datasets. It also preserves the source images this way. \n",
    "    This will also rename all your images. \n",
    "    \n",
    "## Sampling\n",
    "    *get_subset_data*\n",
    "    Sometimes I wanted to grab X number images from another dataset and mix them up with my training data. Like 500 spiders and 1000 anime faces and 200 wikiart. \n",
    "    This is mostly for experimental purposes which is what datascience is all about. \n",
    "    \n",
    "## Removing borders\n",
    "    crop_borders\n",
    "     I created this to remove borders, center crop and resize the image. It's all brute force but mostly works great. \n",
    "    Kaggles datasets are great. But the Anime ones all had black borders to \"square up\" the images.\n",
    "    Took like 12 hours to process 900k images. \n",
    "    **Note** THis will indiscriminately delete images it has issues processing for some reason or other. In 300k+ datasets I didn't feel this was an issue. \n",
    "    **Note** This will also create a newly named image and delete the original. \n",
    "    \n",
    "# Bonus functions\n",
    "    Another major issue I had with data science courses is all your data is loaded into memory. This is fine for small sets like mnist and Van Gogh. \n",
    "    Also using premade datasets lead to issues.\n",
    "    For my own data I simply could not get the iterator to work: \"sample_van_gogh = next(iter(train_van_gogh))\". \n",
    "    So I said F it and wrote load_batch\n",
    "    \n",
    "### load_batch(fileList, batch_size)\n",
    "    Relies on get_list_build_batches. Does what the name says but dynamic. Give it a list of files and batch size. It will pull x images randomly from list. Format them for tensors (-1 +1) and return a batch ready to learn from. \n",
    "    Chances are it will not use every image in every epoch and will use many duplicates. I'll fix this to pop out the data instead. \n",
    "    If for some reason it cannot read the image it will delete it.\n",
    "    If the image is the wrong size it will fix it. \n",
    "    This function does not care about your data, so make sure it's backed up. Give it an incorrect directory, it could wipe your drive. \n",
    "    \n",
    "### get_list_build_batches\n",
    "    Builds a list of ALL your image files in a base directory. Since I sort everything in a subdir of ~2000 files each there will be a lot of subdirectories. This gets them all. like \"datasets/creepy_stuff/000\" and so on. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7185221-cc88-47df-b445-a8685b82b207",
   "metadata": {},
   "source": [
    "## Use\n",
    "    My normal steps are a bit wonky but I'm refining them as things go. \n",
    "    1: Download images from GIS, Kaggle, Wikiart, DEvient art... \n",
    "    2: Sort by landscape or portrait (sort_images_by_alignment.py)\n",
    "    3: Gigapixel is used to resize the images to a standard height/width depending on the smallest dimension (height for landscape...)\n",
    "    4: Save images back to originating folder.\n",
    "    5: Now you can create dataset with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c036dff-4b3c-4324-84a8-0c5aeb651e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, exists\n",
    "from shutil import copy2 as copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "import math\n",
    "import bordercrop as bcrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e100086-78b2-44d1-8106-a4f09cd0bc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\ai\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0732af8-1a0c-4a69-80bb-db59205e060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added to catch decompression BOMB warnings from PIL and simply delete the file in question. \n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb3d57-0095-4b61-b28c-4e9d741e6987",
   "metadata": {},
   "source": [
    "# Helper Function defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfba9a5-882b-48dc-a9c6-a9efcfe5ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newsize(w, h, size):\n",
    "    # if square great!\n",
    "    if w == h:\n",
    "        return (size, size)\n",
    "    \n",
    "    if w > h:\n",
    "        newsize = get_landscape_dim((w,h), size)\n",
    "    else:\n",
    "        newsize = get_portrait_dim((w,h), size)\n",
    "    return newsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb190a4-656f-463b-a837-a3fd680faf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrientation(dimensions):\n",
    "    # True if portrait\n",
    "    if dimensions[0] > dimensions[1]:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08d45e9-f8b3-4b3a-9ca8-5d7129668b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landscape_dim(dims, size):\n",
    "    w, h = dims\n",
    "    scale = size/h\n",
    "    h = size\n",
    "    w = math.floor(w * scale)\n",
    "    if w%2 != 0:\n",
    "        w += 1\n",
    "    return (w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a044936-b444-48ce-b50c-3c77dce278f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portrait_dim(dims, size):\n",
    "    w, h = dims\n",
    "    scale = size/w\n",
    "    h = math.floor(h * scale)\n",
    "    w = size\n",
    "    if h%2 != 0:\n",
    "        h -= 1\n",
    "    return (w,h)\n",
    "  \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d7753b-62fb-442a-9a06-ef7cdc014c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_list(path):\n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            file = file.lower()\n",
    "            if '.jpg' in file or '.png' in file or '.jpeg' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad8d055-9365-4459-afa1-bbbfae36a1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97388b58-36ae-4674-a5d4-6ac09aada1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba3a9fab-d5d5-4291-8a53-492e82bb5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(num_images_to_gen):\n",
    "    # num_images_to_gen long way to say \"Batch size\". \n",
    "    #result = tf.random.normal(shape=[num_images_to_gen, latent_dim])\n",
    "    result = tf.random.normal(shape=[num_images_to_gen, img_width, img_height, channels])\n",
    "    return resultfilesprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b7aef1-dd73-4b9e-bc7f-c287dee9a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_list(path):\n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if '.jpg' in file or '.png' or '.jfif' or '.jpeg' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59e1d330-7c9b-40c4-984b-42a7b5881552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(path, img):\n",
    "    if \"PIL\" not in str(type(img)):\n",
    "        img = Image.fromarray(np.uint8(img*255))\n",
    "    img = img.convert('RGB')\n",
    "    name = name_image(img)\n",
    "    img.save(join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7292a47f-b921-4e90-8087-b10906153231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_image_from_path(path):\n",
    "    img = Image.open(path)\n",
    "    hashedImage = hashlib.md5(img.tobytes()).hexdigest()\n",
    "    img.close()\n",
    "    hashedName = hashedImage + \".\" + \"jpg\"\n",
    "    return hashedName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310d4c92-fc90-41b5-a8c4-968b0bec7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cropping, will probably use this for all images since this is resizing and creating new hash. \n",
    "def name_image(img):\n",
    "    hashedImage = hashlib.md5(img.tobytes()).hexdigest()\n",
    "    hashedName = hashedImage + \".\" + \"jpg\"\n",
    "    return hashedName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ed3b5f2-5c8c-4e19-bfcf-1ee4eb958549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_num_crops(dimensions):\n",
    "    w, h = dimensions\n",
    "    totalCrops = 1\n",
    "    if w > h:\n",
    "        total = (w/h) # total number of crops we can get.\n",
    "    else:\n",
    "        total = (h/w)\n",
    "        \n",
    "    # I can generally get 2-3 good crops from a ratio greater than 1.5.\n",
    "    # Left/top, right/bottom and Center crop with some overlap. \n",
    "    # It will still retun 2 crops (left/right) on a rare occasion. \n",
    "    if total < 2 and total > 1.5: \n",
    "        return 3\n",
    "    else:\n",
    "        return int(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e9d34c-2eab-456b-bebf-64e68e55c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(savepath, img):\n",
    "    w, h = img.size\n",
    "    # no need to crop squares. \n",
    "    if w == h:\n",
    "        return\n",
    "    \n",
    "    num_crops = get_num_crops(img.size)\n",
    "    if num_crops == 0:\n",
    "        print(f\"0 crops for image {img.size}\")\n",
    "    if num_crops <= 3:\n",
    "        one_to_3_crop(savepath, img, num_crops)\n",
    "    else:\n",
    "        multi_crop(savepath, img, num_crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13766a34-3795-4615-a4be-053cad9aa822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial solution so they're all in same cell. I'm sure I can come up with better. \n",
    "crop_type = {'multi':0, 'tri':0, 'center':0}\n",
    "def multi_crop(savepath, img, num_crops):\n",
    "    crop_type['multi'] += 1\n",
    "    # img_width is a global for desired width of final image for dataset. \n",
    "    w, h = img.size\n",
    "    # Setting the points for cropped image\n",
    "    left = 0\n",
    "    top = 0\n",
    "    bottom = h\n",
    "    for i in range(num_crops):\n",
    "        if w > h:\n",
    "            left = img_width * i\n",
    "            right = img_width * (i+1)\n",
    "            if right > w:\n",
    "                diff = right - w\n",
    "                left -= diff\n",
    "                right -= diff\n",
    "                #print(f\"Right exceeds by {diff}\")\n",
    "            cropped = img.crop((left, top, right, bottom))\n",
    "            cropped.resize((img_width, img_height)) # just in case it's 1 off. \n",
    "            save_image(savepath, cropped)\n",
    "        else:\n",
    "            top = img_height * i\n",
    "            bottom = img_height * (i+1)\n",
    "            if bottom > h:\n",
    "                diff = bottom - h\n",
    "                bottom -= diff\n",
    "                top -= diff\n",
    "                #print(f\"Bottom exceeds by {diff}\")\n",
    "            cropped = img.crop((left, top, w, bottom))\n",
    "            cropped.resize((img_width, img_height)) # just in case it's 1 off. \n",
    "            save_image(savepath, cropped)\n",
    "\n",
    "# This may be the most common one.\n",
    "def one_to_3_crop(savepath, img, num_crops):\n",
    "    crop_type['tri'] += 1\n",
    "    # img_width is a global for desired width of final image for dataset. \n",
    "    w, h = img.size\n",
    "\n",
    "    # Setting the points for cropped image\n",
    "    # cropping from left-->right or top-->bottom\n",
    "    left = 0\n",
    "    top = 0\n",
    "    # center always gets called. \n",
    "    # left and Right crops for when 2 are used. \n",
    "    if w > h:\n",
    "        if num_crops == 1 or num_crops == 3:\n",
    "            cropped = crop_center(img)\n",
    "            save_image(savepath, cropped)\n",
    "        if num_crops == 2 or num_crops == 3:\n",
    "            cropped = crop_left(img)\n",
    "            save_image(savepath, cropped)\n",
    "            cropped = crop_right(img)\n",
    "            save_image(savepath, cropped)\n",
    "    else:\n",
    "        if num_crops == 1 or num_crops == 3:\n",
    "            cropped = crop_center(img)\n",
    "            save_image(savepath, cropped)\n",
    "        if num_crops == 2 or num_crops == 3:\n",
    "            cropped = crop_top(img)\n",
    "            save_image(savepath, cropped)\n",
    "            cropped = crop_bottom(img)\n",
    "            save_image(savepath, cropped)\n",
    "\n",
    "# Mostly helper functions but can be used separate.\n",
    "def crop_left(img):\n",
    "    w, h = img.size\n",
    "    cropped = img.crop((0, 0, img_width, h))\n",
    "    return cropped.resize((img_width, img_height))\n",
    "\n",
    "def crop_right(img):\n",
    "    w, h = img.size\n",
    "    cropped = img.crop((w-img_width, 0, w, h))\n",
    "    return cropped.resize((img_width, img_height))\n",
    "\n",
    "def crop_top(img):\n",
    "    w, h = img.size\n",
    "    cropped = img.crop((0, 0, w, img_height))\n",
    "    return cropped.resize((img_width, img_height))\n",
    "\n",
    "def crop_bottom(img):\n",
    "    w, h = img.size\n",
    "    cropped = img.crop((0, h-img_height, w, h))\n",
    "    return cropped.resize((img_width, img_height))\n",
    "\n",
    "# landscape center\n",
    "def crop_l_center(img):\n",
    "    crop_type['center'] += 1\n",
    "    w, h = img.size\n",
    "    center = math.floor(w/2)\n",
    "    left = math.floor(center - (img_width/2))\n",
    "    right = math.floor(center + (img_width/2))\n",
    "    img = img.crop((left, 0, right, h))\n",
    "    return img\n",
    "\n",
    "# portrait center\n",
    "def crop_p_center(img):\n",
    "    w, h = img.size\n",
    "    center = math.floor(h/2)\n",
    "    top = math.floor(center - (img_height/2))\n",
    "    bottom = math.floor(center + (img_height/2))\n",
    "    img = img.crop((0, top, w, bottom))\n",
    "    return img\n",
    "\n",
    "# Helper Function\n",
    "def crop_center(img):\n",
    "    w, h = img.size\n",
    "    if w > h:\n",
    "        cropped = crop_l_center(img)\n",
    "    else:\n",
    "        cropped = crop_p_center(img)\n",
    "    return cropped.resize((img_width, img_height))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7b43da-01d4-4009-8d4e-3d2db9510c60",
   "metadata": {},
   "source": [
    "# GAN carryover functions that I didn't feel like deleting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3a2a98-7c6b-4e69-9963-d5d0cb0f98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just carry over from my GAN notebook. \n",
    "seed = int(time.time())\n",
    "def plant_seeds(seed=seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "plant_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9693d5ce-090f-42c8-adec-6e97106646eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_build_batches():\n",
    "    print(\"Getting file list and factoring how many batches per Epoch. \")\n",
    "    imageFiles = get_images_list(resized_path)\n",
    "    epoch_batches = int(len(imageFiles) / batch_size )\n",
    "    epoch_batches = epoch_batches - (epoch_batches % batch_size)\n",
    "    return imageFiles, epoch_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6651f11f-7a00-4a9b-8725-0a474bf53001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(num_images_to_gen):\n",
    "    # num_images_to_gen long way to say \"Batch size\". \n",
    "    #result = tf.random.normal(shape=[num_images_to_gen, latent_dim])\n",
    "    result = tf.random.normal(shape=[num_images_to_gen, Config.img_width, Config.img_height, Config.channels])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4f8b192-5dfe-4f24-9fb5-544ad3ceabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode a single image in a TFRecord\n",
    "# It also standardizes the image\n",
    "def decode_image(image) -> tf.Tensor:\n",
    "    #img = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    img = image / 127.5 - 1\n",
    "    print(type(img))\n",
    "    img = tf.reshape(img, [Config.img_width, Config.img_height, Config.channels])\n",
    "    #print(img.shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50d970ed-bb60-4299-8d6e-e56b70e760b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is technically how you're supposed to do it. \n",
    "# I don't use this function.\n",
    "def dataset_from_dir(dataset_folder, ordered=False):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        dataset_folder,\n",
    "        labels=None,\n",
    "        #validation_split=0.2,\n",
    "        #subset=\"training\",\n",
    "        shuffle = False,\n",
    "        seed=Config.seed,\n",
    "        image_size=(Config.img_height, Config.img_width),\n",
    "        batch_size=1) # batch size is one because anything different added another dimension to the dataset. \n",
    "    dataset = dataset.map(decode_image)\n",
    "    dataset = dataset.cache()\n",
    "    #dataset.shuffle(2048)\n",
    "    return dataset.batch(Config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89ba2d15-4587-49b3-9171-d15c39000e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab was running out of memory because the datasets were huge. This solves that. \n",
    "def load_batch(fileList, batchSize):\n",
    "    array = []\n",
    "    for i in range(batchSize):\n",
    "        # if there is less than 3 color channels, keep trying. \n",
    "        while True:\n",
    "            file = random.choice(fileList)\n",
    "            image = Image.open(file)\n",
    "            if len(image.split()) != 3:\n",
    "                print(f\"removing {file}\")\n",
    "                os.remove(file)\n",
    "                imageFiles, epoch_batches = get_list_build_batches()\n",
    "            else:\n",
    "                break\n",
    "        data = np.asarray(image)\n",
    "        data = data / 127.5 -1.\n",
    "        #print(data)\n",
    "        array.append(data)\n",
    "\n",
    "    train = np.array(array, dtype=np.float32)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca91d7c-a0c5-44e3-a073-2f04d8c7960d",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e238e076-0b05-40ac-9b45-601e42f00e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes the decision for you. \n",
    "\n",
    "def sort_or_resize(inpath, delete_when_done = False):\n",
    "    sorting = False\n",
    "    fileList = get_images_list(inpath)\n",
    "    # print(len(fileList))\n",
    "    \n",
    "    # Sample 10 random images and decide if sorting or resize/cropping. Not exactly perfect. \n",
    "    # TODO this can just be merged and streamlined without all these tests. If image square, then just sort \n",
    "    for i in range(10):\n",
    "        img = Image.open(random.choice(fileList))\n",
    "        w, h = img.size\n",
    "        img.close()\n",
    "        if w == img_width and h == img_height:\n",
    "            sorting = True\n",
    "\n",
    "    if sorting == True:\n",
    "        print(\"sorting...\")\n",
    "        sort_images(images_path, delete_when_done)\n",
    "    else:\n",
    "        print(\"Resizing...\")\n",
    "        resize_and_crop(images_path, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d234e645-e052-490f-a7ad-5cf168b68c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_images(inpath, delete_when_done):\n",
    "    outpath = inpath + f\"_{img_width}_dataset\"\n",
    "    subdir_num = 0\n",
    "    filesprocessed = 0\n",
    "    if not exists(outpath):\n",
    "        print(f\"Creating {outpath}\")\n",
    "        os.mkdir(outpath)\n",
    "    \n",
    "    fileList = get_images_list(inpath)\n",
    "    print(f\"Copying {len(fileList)} images\")\n",
    "    \n",
    "    for filename in fileList:\n",
    "        if filesprocessed % 2000 == 0:\n",
    "            print(f\"Files processed {filesprocessed}, dir num {subdir_num}\")\n",
    "            subdir_name = f\"{subdir_num}\".zfill(5)\n",
    "            savedir = join(outpath, subdir_name)\n",
    "            if not exists(savedir):\n",
    "                os.mkdir(savedir)\n",
    "            subdir_num += 1\n",
    "        newname = name_image_from_path(filename)\n",
    "        copy(filename, join(savedir, newname))\n",
    "        if delete_when_done:\n",
    "            os.remove(filename)\n",
    "        filesprocessed += 1\n",
    "\n",
    "    print(f\"Done, total files processed {filesprocessed}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7822b83c-8327-445e-b548-b7dae05d9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case size will be the smallest dimension of image. \n",
    "def resize_and_crop(inpath, size):\n",
    "    outpath = inpath + f\"_{img_width}_dataset\"\n",
    "    subdir_num = 0\n",
    "    filesprocessed = 0\n",
    "    if not exists(outpath):\n",
    "        print(f\"Creating {outpath}\")\n",
    "        os.mkdir(outpath)\n",
    "    \n",
    "    fileList = get_images_list(inpath)\n",
    "    print(f\"Resizing {len(fileList)} images\")\n",
    "    \n",
    "    for filename in fileList:\n",
    "        if filesprocessed % 2000 == 0:\n",
    "            print(f\"Files processed {filesprocessed}, dir num {subdir_num}\")\n",
    "            subdir_name = f\"{subdir_num}\".zfill(5)\n",
    "            savedir = join(outpath, subdir_name)\n",
    "            if not exists(savedir):\n",
    "                os.mkdir(savedir)\n",
    "            subdir_num += 1\n",
    "            \n",
    "        try:\n",
    "            img = Image.open(filename)\n",
    "        except:\n",
    "            print(f\"Cannot open {filename}... removing.\")\n",
    "            if exists(filename):\n",
    "                os.remove(filename)\n",
    "            continue\n",
    "        # Crap I have to do maths.\n",
    "        w, h = img.size\n",
    "        \n",
    "        newsize = get_newsize(w, h, img_width) # only need one really since we're making squares. \n",
    "\n",
    "        try:\n",
    "            img = img.resize(newsize)\n",
    "        except:\n",
    "            print(f\"Failed to resize {filename} to {newsize}\")\n",
    "            img.close()\n",
    "            #os.remove(filename)\n",
    "            continue\n",
    "\n",
    "        if w != h:\n",
    "            crop(savedir, img)\n",
    "        else:\n",
    "            name = name_image(img)\n",
    "            img.save(join(savedir, name))\n",
    "        img.close()\n",
    "        filesprocessed += 1\n",
    "\n",
    "    print(f\"Done, total files processed {filesprocessed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbf1affe-96e1-49b6-8732-625017c7f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is in place and destructive. \n",
    "def crop_borders(inpath):\n",
    "    filesprocessed = 0\n",
    "    deleted = 0\n",
    "    fileList = get_images_list(inpath)\n",
    "    print(f\"Croping border of {len(fileList)} images\")\n",
    "    \n",
    "    for filename in fileList:\n",
    "        if filesprocessed % 1000 == 0:\n",
    "            print(f\"***** Processed {filesprocessed} files so far. {len(fileList) - filesprocessed} files left.\")\n",
    "        # Crop\n",
    "        try:\n",
    "            img = Image.open(filename)\n",
    "        except:\n",
    "            if exists(filename):\n",
    "                os.remove(filename)\n",
    "                deleted += 1\n",
    "            continue\n",
    "        try:\n",
    "            img = bcrop.crop(img, MINIMUM_THRESHOLD_HITTING=500, MINIMUM_ROWS=2) # dealing with 512 or smaller images so thin border is expected.\n",
    "        except:\n",
    "            # print(\"Issue cropping. Removing bad image;\")\n",
    "            img.close()\n",
    "            os.remove(filename)\n",
    "            deleted += 1\n",
    "            continue\n",
    "        \n",
    "        # resize for \n",
    "        w, h = img.size\n",
    "        \n",
    "        # Image is either too small or cropped to 0x0. \n",
    "        if w < 200 or h < 200:\n",
    "            # print(f\"crop issue with {filename}\")\n",
    "            img.close()\n",
    "            os.remove(filename)\n",
    "            deleted += 1\n",
    "            continue\n",
    "\n",
    "        newsize = get_newsize(w, h, img_width)\n",
    "        if newsize[0] < 512 or newsize[1] < 512:\n",
    "            print(f\"newsize is off {newsize[0]}\")\n",
    "        img.resize(newsize)\n",
    "        img = crop_center(img)\n",
    "        \n",
    "        # now image can be named and saved. \n",
    "        filepath = \"\\\\\".join(filename.split(\"\\\\\")[:-1])\n",
    "        newname = name_image(img)\n",
    "        newname = join(filepath, newname)\n",
    "        \n",
    "        # remove old uncropped image. \n",
    "        if newname != filename:\n",
    "            os.remove(filename) \n",
    "        # save image. If same name it should save over it. \n",
    "        #print(f\"saving to: {newname}\")\n",
    "        img.save(newname)\n",
    "        filesprocessed += 1\n",
    "\n",
    "    print(f\"Done, total files processed {filesprocessed}, {deleted} files were deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed7e0c9e-50b3-4b80-bafb-3d1038a779fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically a function to grab X random images from source dataset and drop it into the current working dataset for diversity.\n",
    "# I used to just grab a few random rows and be done. This is obviously less lazy than me. \n",
    "def get_subset_data(inpath, outpath, num):\n",
    "    fileList = get_images_list(inpath)\n",
    "    for i in range(num):\n",
    "        copy(random.choice(fileList), outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b38bf7-8281-499e-86f2-db9a822de57f",
   "metadata": {},
   "source": [
    "# Main stuff\n",
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1643e9a-bfee-43ba-bc2b-f3cbeb6cf95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 256\n",
    "img_height = 256\n",
    "channels = 3\n",
    "img_shape = (img_width, img_height, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d427a08b-0264-4e83-80c7-a0405e435f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"F:\\\\machine_learning\\\\datasets\"\n",
    "\n",
    "#images_path = \"F:\\\\machine_learning\\\\datasets\\\\resize_test\" # testing\n",
    "# Directory where images needing scaling are located. \n",
    "#images_path = join(dataset_path, \"mythological-painting\")\n",
    "images_path = join(dataset_path, \"anime_full_body_1024_dataset\")\n",
    "\n",
    "# I'm doing a discriminator and generator dataset thing. \n",
    "current_dataset = join(dataset_path, \"current_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114f8be-f4e7-4ed2-9ec3-9874f7f3df0b",
   "metadata": {},
   "source": [
    "## The functions that do all the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9997946-64de-4349-9d75-aa3633770b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing...\n",
      "Creating F:\\machine_learning\\datasets\\anime_full_body_1024_dataset_512_dataset\n",
      "Resizing 14172 images\n",
      "Files processed 0, dir num 0\n",
      "Files processed 2000, dir num 1\n",
      "Files processed 4000, dir num 2\n",
      "Files processed 6000, dir num 3\n",
      "Files processed 8000, dir num 4\n",
      "Files processed 10000, dir num 5\n",
      "Files processed 12000, dir num 6\n",
      "Files processed 14000, dir num 7\n",
      "Done, total files processed 14172\n"
     ]
    }
   ],
   "source": [
    "# If you set the flag to True, it will delete the source images. \n",
    "# Why?!? Because I had directories with 200,000+ files moving to a cleaner directory structure. Manually deleting those after would lock up my system for what seemed like hours **ADHD time. (5 minutes in real time.)\n",
    "\n",
    "sort_or_resize(images_path, False) # False is do not delete original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc8f31-c7e6-4a48-8016-a891d4b1c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies x nun files from a dataset into current_dataset \n",
    "\n",
    "#get_subset_data(images_path, current_dataset, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb56351-0ea4-4a26-969f-dce5779a77c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop_borders(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba3566-2507-49d9-9cb8-7d32a007fed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfbfb19-747a-43d3-a56e-492fe72e29e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd88e391-cfdf-40d1-9758-777d2927173d",
   "metadata": {},
   "source": [
    "# Scratch space\n",
    "    Jupyter's power is in visualizing data line by line. \n",
    "    That is what I do here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60a66b-b1ea-4e88-a91b-2562fc62b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# height_test.jpg width_test.jpg\n",
    "test_dir = \"F:\\\\machine_learning\\\\datasets\\\\anime_hires_faces_dataset\\\\00004\"\n",
    "test_dir = \"F:\\\\machine_learning\\\\datasets\\\\feet_dataset\\\\00001\"\n",
    "testimg = join(test_dir, \"0cf7de6790a43ae663205b0ba319ca7b.jpg\")\n",
    "\n",
    "testimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768e878-e32e-4bff-9648-03a3c80c8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(testimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e81713-5ea2-40c4-86fa-c1432fb06abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1593f-9676-4f1d-b697-91c16ef2a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\\\\\".join(images_path.split(\"\\\\\")[:-1])\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf32fa-25a0-4b75-a0c8-7bdab40ff7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = bcrop.crop(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00654020-f280-4218-8b41-c3d784324eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = Image.open(testimg)\n",
    "#image = crop_p_center(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59936f1-27ac-44dc-8473-b949a5dca0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im.crop((left, top, right, bottom))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cce2d5-0836-4823-b49c-8c27badc9c5f",
   "#Initialize variables\n",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
